import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_curve,
    auc,
    precision_recall_curve
)

from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans


import pandas as pd


df = pd.read_csv("bank-full.csv", sep=';')


df['Purchase'] = df['y'].map({'yes': 'Yes', 'no': 'No'})


df.head()

df["y_enc"] = df["y"].map({"no": 0, "yes": 1})

sns.countplot(x="y", data=df)
plt.title("Target Variable Distribution")
plt.show()

df.hist(figsize=(14,10))
plt.tight_layout()
plt.show()

plt.figure(figsize=(8,5))
sns.histplot(df["age"], bins=30, kde=True)
plt.title("Distribution of Customer Age")
plt.xlabel("Age")
plt.ylabel("Count")
plt.show()

categorical_cols = ["job", "marital", "education", "housing", "loan"]

for col in categorical_cols:
    plt.figure(figsize=(6,4))
    sns.countplot(y=col, data=df)
    plt.title(f"Distribution of {col}")
    plt.show()

plt.figure(figsize=(10,6))
sns.heatmap(
    df.select_dtypes(include=["int64", "float64"]).corr(),
    cmap="coolwarm",
    annot=True
)
plt.title("Correlation Heatmap (Numerical Features)")
plt.show()

categorical_cols = df.select_dtypes(include="object").columns
categorical_cols = categorical_cols.drop("y")

numerical_cols = df.select_dtypes(include=["int64", "float64"]).columns
numerical_cols

categorical_cols = df.select_dtypes(include="object").columns
categorical_cols = categorical_cols.drop("y")

numerical_cols = df.select_dtypes(include=["int64", "float64"]).columns
numerical_cols

df_encoded = pd.get_dummies(
    df,
    columns=categorical_cols,
    drop_first=True
)

X = df_encoded.drop(columns=["y", "y_enc"])
y = df_encoded["y_enc"]

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = RandomForestClassifier(
    n_estimators=200,
    random_state=42,
    class_weight="balanced"
)

model.fit(X_train_scaled, y_train)

y_pred = model.predict(X_test_scaled)
y_scores = model.predict_proba(X_test_scaled)[:, 1]

print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()
cm_norm = confusion_matrix(y_test, y_pred, normalize="true")

plt.figure(figsize=(6,4))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Greens")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Normalized Confusion Matrix")
plt.show()

fpr, tpr, _ = roc_curve(y_test, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
plt.plot([0,1], [0,1], linestyle="--", color="black")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

precision, recall, _ = precision_recall_curve(y_test, y_scores)

plt.figure(figsize=(6,4))
plt.plot(recall, precision)
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precisionâ€“Recall Curve")
plt.show()

importances = pd.Series(
    model.feature_importances_,
    index=X.columns
).sort_values(ascending=False)

top_features = importances.head(15)

plt.figure(figsize=(10,6))
top_features.plot(kind="barh")
plt.gca().invert_yaxis()
plt.xlabel("Importance Score")
plt.title("Top 15 Feature Importances")
plt.show()

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_train_scaled)

plt.figure(figsize=(8,6))
plt.scatter(
    X_pca[:,0],
    X_pca[:,1],
    c=y_train,
    cmap="coolwarm",
    alpha=0.6
)
plt.xlabel("PC 1")
plt.ylabel("PC 2")
plt.title("PCA Visualization of Bank Customers")
plt.show()

kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_pca)

plt.figure(figsize=(8,6))
plt.scatter(
    X_pca[:,0],
    X_pca[:,1],
    c=clusters,
    cmap="viridis",
    alpha=0.7
)
plt.xlabel("PC 1")
plt.ylabel("PC 2")
plt.title("Customer Segmentation using K-Means")
plt.show()

cluster_df = pd.DataFrame(X_train, columns=X.columns)
cluster_df["cluster"] = clusters

cluster_df.groupby("cluster").mean()

